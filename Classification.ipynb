{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('pickled'):\n",
    "    os.makedirs('pickled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading melanoma data\n",
    "posimages = os.listdir(\"melanoma/\")\n",
    "data = []\n",
    "labels = []\n",
    "if not os.path.exists('pickled/data.pkl'):\n",
    "    for file in posimages:\n",
    "        image = cv2.imread(\"melanoma/\" + file)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(1)\n",
    "\n",
    "    negimages = os.listdir(\"others/\")\n",
    "    for file in negimages:\n",
    "        image = cv2.imread(\"others/\" + file)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "        labels.append(0)\n",
    "        \n",
    "    d = {}\n",
    "    d['data'] = data\n",
    "    d['labels'] = labels\n",
    "    pickle.dump(d, open('pickled/data.pkl', 'wb'))\n",
    "else:\n",
    "    d = pickle.load(open( 'pickled/data.pkl', 'rb'))\n",
    "    data = d['data']\n",
    "    labels = d['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data,labels, test_size=0.40, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Of the Model\n",
    "\n",
    "LAYER 1\n",
    "A 2D CNN layer with activation function of RelU 32 neurons, kernel size 5X5. Maxpooling and strides are taken for downsampling.\n",
    "LAYER 2\n",
    "A 2D CNN Layer with activation function sigmoid and 64 neurons.\n",
    "LAYER 3\n",
    "Dropout layer to prevent overfitting\n",
    "LAYER 4\n",
    "A dense layer with 64 neurons\n",
    "LAYER 5\n",
    "The final layer with softmax activation function and 2 neurons for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1200, 64, 64, 3)\n",
      "1200 train samples\n",
      "800 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),strides = (2,2), activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2*r*p/(r+p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compiling model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', precision, recall, f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.6335 - acc: 0.5192 - precision: 0.5192 - recall: 0.5192 - f1score: 0.5192 - val_loss: 0.6943 - val_acc: 0.1900 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1score: 0.6667\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.6345 - acc: 0.4725 - precision: 0.5797 - recall: 0.8550 - f1score: 0.6887 - val_loss: 0.6910 - val_acc: 0.8100 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1score: 0.6667\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.6332 - acc: 0.5050 - precision: 0.6067 - recall: 0.9175 - f1score: 0.7300 - val_loss: 0.6891 - val_acc: 0.8100 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1score: 0.6667\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.6338 - acc: 0.4700 - precision: 0.5938 - recall: 0.9092 - f1score: 0.7180 - val_loss: 0.6865 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.6332 - acc: 0.8017 - precision: 0.6003 - recall: 0.9108 - f1score: 0.7235 - val_loss: 0.6841 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.6330 - acc: 0.8150 - precision: 0.6002 - recall: 0.9125 - f1score: 0.7237 - val_loss: 0.6817 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.6329 - acc: 0.8150 - precision: 0.6703 - recall: 0.8792 - f1score: 0.7537 - val_loss: 0.6798 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.6323 - acc: 0.8150 - precision: 0.8150 - recall: 0.8150 - f1score: 0.8150 - val_loss: 0.6779 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.6325 - acc: 0.8150 - precision: 0.8150 - recall: 0.8150 - f1score: 0.8150 - val_loss: 0.6757 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.6323 - acc: 0.8150 - precision: 0.8150 - recall: 0.8150 - f1score: 0.8150 - val_loss: 0.6742 - val_acc: 0.8100 - val_precision: 0.8100 - val_recall: 0.8100 - val_f1score: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5042eb550>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training and testing model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.674210689068\n",
      "Test F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test F1 score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
